import streamlit as st
import openai
from PIL import Image
import io
import base64
import pandas as pd
import json
import os
import concurrent.futures
import re

# ğŸ” OpenAI API í‚¤ ì„¤ì • (í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¶ˆëŸ¬ì˜´)
openai.api_key = os.environ.get("OPENAI_API_KEY")

# ğŸ“¦ GPT Vision ì´ë¯¸ì§€ ë¶„ì„ í•¨ìˆ˜ (ìµœì í™” ë²„ì „)
def extract_info_from_image(image: Image.Image) -> dict:
    try:
        # ì´ë¯¸ì§€ â†’ base64
        buffered = io.BytesIO()
        image.save(buffered, format="PNG")
        img_b64 = base64.b64encode(buffered.getvalue()).decode()

        # GPT-4o Vision í˜¸ì¶œ
        response = openai.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "system",
                    "content": "You are a helpful assistant extracting brand/company name and article numbers from fabric swatch images."
                },
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": (
                                "Extract only the **brand/company name** and **article number(s)** from the fabric swatch image.\n\n"
                                "Company names often contain: Co.,Ltd., TEXTILE, Inc., æ ªå¼ä¼šç¤¾\n"
                                "Article numbers usually look like: BD3991, TXAB-H062, 7025-610-3\n\n"
                                "âœ… Return this JSON only:\n"
                                "{ \"company\": \"<Company>\", \"article_numbers\": [\"<article1>\", \"<article2>\"] }\n\n"
                                "If not found, return:\n"
                                "{ \"company\": \"N/A\", \"article_numbers\": [\"N/A\"] }"
                            )
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/png;base64,{img_b64}"
                            }
                        }
                    ]
                }
            ],
            max_tokens=500
        )

        result_text = response.choices[0].message.content.strip()
        print("ğŸ§¾ GPT ì‘ë‹µ:", result_text)

        # 1ì°¨ JSON íŒŒì‹± ì‹œë„
        try:
            return json.loads(result_text)
        except json.JSONDecodeError:
            # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ìˆ˜ë™ ì¶”ì¶œ
            company_match = re.search(r'"company"\s*:\s*"([^"]+)"', result_text)
            article_matches = re.findall(r'"([A-Z0-9\-]{4,})"', result_text)

            return {
                "company": company_match.group(1).strip() if company_match else "[ERROR: Invalid JSON]",
                "article_numbers": list(set(article_matches)) if article_matches else ["[ERROR: Invalid JSON]"]
            }

    except Exception as e:
        return {
            "company": "[ERROR]",
            "article_numbers": [f"[ERROR] {str(e)}"]
        }

# ğŸŒ Streamlit ì›¹ì•± UI
st.set_page_config(page_title="Object Swatch OCR", layout="wide")
st.image("https://object-tex.com/_nuxt/img/logo-black.40d9d15.svg", width=150)
st.title("ğŸ“¦ Object Swatch OCR")
st.markdown("ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ë©´ íšŒì‚¬ëª…ê³¼ í’ˆë²ˆ(Article No)ì„ ìë™ìœ¼ë¡œ ì¸ì‹í•˜ê³  ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.")

uploaded_files = st.file_uploader("ì´ë¯¸ì§€ ì—…ë¡œë“œ", type=["png", "jpg", "jpeg"], accept_multiple_files=True)

if uploaded_files:
    st.subheader("â³ ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...")
    results = []
    progress = st.progress(0)

    def process_image(i_file):
        image = Image.open(i_file)
        result = extract_info_from_image(image)
        return {
            "íŒŒì¼ëª…": i_file.name,
            "ë¸Œëœë“œëª…": result.get("company", "N/A"),
            "í’ˆë²ˆ": ", ".join(result.get("article_numbers", []))
        }

    # ğŸ”„ ë³‘ë ¬ ì²˜ë¦¬ë¡œ ì†ë„ í–¥ìƒ
    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
        future_map = {executor.submit(process_image, f): f.name for f in uploaded_files}
        for i, future in enumerate(concurrent.futures.as_completed(future_map)):
            try:
                results.append(future.result())
            except Exception as e:
                results.append({
                    "íŒŒì¼ëª…": future_map[future],
                    "ë¸Œëœë“œëª…": "[ERROR]",
                    "í’ˆë²ˆ": f"[ERROR] {str(e)}"
                })
            progress.progress((i + 1) / len(uploaded_files))

    # ğŸ“Š ê²°ê³¼ ì¶œë ¥
    df = pd.DataFrame(results)
    st.success("âœ… ë¶„ì„ ì™„ë£Œ!")
    st.dataframe(df, use_container_width=True)

    # ğŸ“¥ CSV ë‹¤ìš´ë¡œë“œ
    csv = df.to_csv(index=False).encode("utf-8-sig")
    st.download_button(
        "ğŸ“¥ ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ",
        data=csv,
        file_name="swatch_ocr_results.csv",
        mime="text/csv"
    )

