import zipfile

# ë‹¤ì‹œ ì‹¤í–‰ í™˜ê²½ ì´ˆê¸°í™”ë¨ â†’ íŒŒì¼ ì¬ìƒì„±
final_code_files = {
    "app.py": """
import streamlit as st
import openai
from PIL import Image
import io
import base64
import pandas as pd
import json
import os
import concurrent.futures
import re

# ğŸ” OpenAI API í‚¤ ì„¤ì •
openai.api_key = os.environ.get("OPENAI_API_KEY")

# âœ… ì‘ë‹µ ì•ˆì „ íŒŒì‹± í•¨ìˆ˜
def safe_parse_response(result_text: str) -> dict:
    try:
        return json.loads(result_text)
    except json.JSONDecodeError:
        company_match = re.search(r'"company"\\s*:\\s*"([^"]+)"', result_text)
        articles = re.findall(r'"([A-Z0-9\\-]{4,})"', result_text)
        return {
            "company": company_match.group(1).strip() if company_match else "[ERROR: Invalid JSON]",
            "article_numbers": list(set(articles)) if articles else ["[ERROR: Invalid JSON]"]
        }

# ğŸ“¦ GPT Vision ì´ë¯¸ì§€ ë¶„ì„ í•¨ìˆ˜
def extract_info_from_image(image: Image.Image) -> dict:
    try:
        buffered = io.BytesIO()
        image.save(buffered, format="PNG")
        img_b64 = base64.b64encode(buffered.getvalue()).decode()

        response = openai.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "system",
                    "content": "You're an assistant extracting company name and fabric article numbers from fabric swatch images."
                },
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": (
                                "Please extract the brand/company name and the fabric article number(s) from this image. "
                                "Company names often include terms like 'Co.,Ltd.', 'Inc.', 'TEXTILE', 'æ ªå¼ä¼šç¤¾', etc. "
                                "Article numbers usually look like 'AB-EX171', 'BD3991', '7025-610-3', and so on.\\n\\n"
                                "Return in this exact JSON format:\\n"
                                "{ \\"company\\": \\"<Company Name>\\", \\"article_numbers\\": [\\"<article1>\\", \\"<article2>\\"] }\\n"
                                "If nothing is found, return 'N/A'."
                            )
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/png;base64,{img_b64}"
                            }
                        }
                    ]
                }
            ],
            max_tokens=300,
        )

        result_text = response.choices[0].message.content.strip()
        return safe_parse_response(result_text)

    except Exception as e:
        return {
            "company": "[ERROR]",
            "article_numbers": [f"[ERROR] {str(e)}"]
        }

# ğŸŒ Streamlit ì›¹ì•±
st.set_page_config(page_title="Object Swatch OCR", layout="wide")
st.image("https://object-tex.com/_nuxt/img/logo-black.40d9d15.svg", width=150)
st.title("ğŸ“¦ Object Swatch OCR")
st.markdown("ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ë©´ íšŒì‚¬ëª…ê³¼ í’ˆë²ˆ(Article No)ì„ ìë™ìœ¼ë¡œ ì¸ì‹í•˜ê³  ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.")

uploaded_files = st.file_uploader("ì´ë¯¸ì§€ ì—…ë¡œë“œ", type=["png", "jpg", "jpeg"], accept_multiple_files=True)

if uploaded_files:
    st.subheader("â³ ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...")
    results = []
    progress = st.progress(0)

    def process_image(i_file):
        image = Image.open(i_file)
        result = extract_info_from_image(image)
        return {
            "íŒŒì¼ëª…": i_file.name,
            "ë¸Œëœë“œëª…": result.get("company", "N/A"),
            "í’ˆë²ˆ": ", ".join(result.get("article_numbers", []))
        }

    # ğŸ”„ ë³‘ë ¬ ì²˜ë¦¬
    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
        future_map = {executor.submit(process_image, f): f.name for f in uploaded_files}
        for i, future in enumerate(concurrent.futures.as_completed(future_map)):
            try:
                results.append(future.result())
            except Exception as e:
                results.append({
                    "íŒŒì¼ëª…": future_map[future],
                    "ë¸Œëœë“œëª…": "[ERROR]",
                    "í’ˆë²ˆ": f"[ERROR] {str(e)}"
                })
            progress.progress((i + 1) / len(uploaded_files))

    # ğŸ§¾ ê²°ê³¼ ì¶œë ¥
    df = pd.DataFrame(results)
    st.success("âœ… ë¶„ì„ ì™„ë£Œ!")
    st.dataframe(df, use_container_width=True)

    csv = df.to_csv(index=False).encode("utf-8-sig")
    st.download_button("ğŸ“¥ ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ", data=csv, file_name="swatch_ocr_results.csv", mime="text/csv")
""",
    "requirements.txt": """
streamlit
openai
Pillow
pandas
""",
    "Dockerfile": """
FROM python:3.10-slim

WORKDIR /app

COPY requirements.txt ./
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

EXPOSE 8080
CMD ["streamlit", "run", "app.py", "--server.port=8080", "--server.enableCORS=false", "--server.address=0.0.0.0"]
"""
}

# zipìœ¼ë¡œ ì €ì¥
output_zip_path = "/mnt/data/object_swatch_ocr_final.zip"
with zipfile.ZipFile(output_zip_path, "w") as zipf:
    for filename, content in final_code_files.items():
        file_path = f"/mnt/data/{filename}"
        with open(file_path, "w") as f:
            f.write(content.strip())
        zipf.write(file_path, arcname=filename)

output_zip_path

